{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"ddpg.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"sz_r6QEqZz66"},"source":["If you run in jupyter, turn \n","\n","```\n","colab = False\n","```\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xnK9tUehZqJ0","executionInfo":{"status":"ok","timestamp":1627112942455,"user_tz":-540,"elapsed":19329,"user":{"displayName":"­박민규 / 학생 / 전기·정보공학부","photoUrl":"","userId":"15454198223134513846"}},"outputId":"34155131-e483-4986-ee91-2b83d59f3d66"},"source":["colab = True\n","if colab:\n","    !pip install gym pyvirtualdisplay > /dev/null 2>&1\n","    !apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n","    !apt-get update > /dev/null 2>&1\n","    !apt-get install cmake > /dev/null 2>&1\n","    !pip install --upgrade setuptools 2>&1\n","    !pip install ez_setup > /dev/null 2>&1\n","    !pip3 install box2d-py\n","    !pip3 install gym[Box_2D]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n","Requirement already satisfied: box2d-py in /usr/local/lib/python3.7/dist-packages (2.3.8)\n","Requirement already satisfied: gym[Box_2D] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n","\u001b[33mWARNING: gym 0.17.3 does not provide the extra 'box_2d'\u001b[0m\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.19.5)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.5.0)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.3.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.4.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[Box_2D]) (0.16.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zgztXeWhaDfB","executionInfo":{"status":"ok","timestamp":1627112985288,"user_tz":-540,"elapsed":366,"user":{"displayName":"­박민규 / 학생 / 전기·정보공학부","photoUrl":"","userId":"15454198223134513846"}},"outputId":"7b2538f0-5d1e-4524-d327-cf22d232acbf"},"source":["if colab:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","\n","    %cd /content/drive/MyDrive/Colab\\ Notebooks/rl-master/day3/ddpg\n","    !ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Colab Notebooks/rl-master/day3/ddpg\n","buffer.py  ddpg.ipynb  __pycache__  snapshots  utils.py  video\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"raPrcmjpZePo"},"source":["import torch\n","import torch.nn as nn\n","from torch.nn import MSELoss\n","import torch.nn.functional as F\n","import copy\n","import os\n","import numpy as np\n","from tqdm import tqdm\n","import torch\n","from torch.optim import Adam\n","from buffer import ReplayBuffer\n","from utils import save_snapshot, recover_snapshot, load_model\n","import gym"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sEmB9tRLZePr","executionInfo":{"status":"ok","timestamp":1627112986271,"user_tz":-540,"elapsed":15,"user":{"displayName":"­박민규 / 학생 / 전기·정보공학부","photoUrl":"","userId":"15454198223134513846"}},"outputId":"42bdbe2f-c3ec-475e-b18b-e72b4036f105"},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print('current device =', device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["current device = cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"n5dTtQn-ZePs"},"source":["# 0. Define Q-network & policy-network"]},{"cell_type":"code","metadata":{"id":"sTHHxIokZePt"},"source":["# critic network definition\n","# multi-layer perceptron (with 2 hidden layers)\n","class Critic(nn.Module):\n","    def __init__(self, obs_dim, act_dim, hidden1, hidden2):\n","        super(Critic, self).__init__()\n","        self.fc1 = nn.Linear(obs_dim + act_dim, hidden1)\n","        self.fc2 = nn.Linear(hidden1, hidden2)\n","        self.fc3 = nn.Linear(hidden2, 1)\n","        \n","    \n","    def forward(self, obs, act):\n","        x = torch.cat([obs, act], dim=1)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        \n","        return self.fc3(x)\n","    \n","    \n","# actor network definition\n","# multi-layer perceptron (with 2 hidden layers)\n","class Actor(nn.Module):\n","    def __init__(self, obs_dim, act_dim, ctrl_range, hidden1, hidden2):\n","        super(Actor, self).__init__()\n","        self.fc1 = nn.Linear(obs_dim, hidden1)\n","        self.fc2 = nn.Linear(hidden1, hidden2)\n","        self.fc3 = nn.Linear(hidden2, act_dim)\n","        self.ctrl_range = ctrl_range\n","        \n","    def forward(self, obs):\n","        x = F.relu(self.fc1(obs))\n","        x = F.relu(self.fc2(x))\n","        \n","        return self.ctrl_range * torch.tanh(self.fc3(x))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZKvObdk4ZePu"},"source":["# 1. Define DDPG agent"]},{"cell_type":"code","metadata":{"id":"3pZYZQr1ZePu"},"source":["class DDPGAgent:\n","    def __init__(self, obs_dim, act_dim, ctrl_range, hidden1, hidden2):\n","        \n","        # networks\n","        self.actor = Actor(obs_dim, act_dim, ctrl_range, hidden1, hidden2).to(device)\n","        self.critic = Critic(obs_dim, act_dim, hidden1, hidden2).to(device)\n","                \n","    def act(self, obs):\n","        # numpy ndarray to torch tensor\n","        # we first add an extra dimension\n","        obs = obs[np.newaxis, ...]\n","        with torch.no_grad():\n","            obs_tensor = torch.Tensor(obs).to(device)\n","            # TODO : get agent action from policy network (self.actor)\n","            #act_tensor = \n","\n","        # torch tensor to numpy ndarray\n","        # remove extra dimension\n","        action = act_tensor.cpu().detach().numpy()\n","        action = np.squeeze(action, axis=0)\n","        \n","        return action\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vReax398ZePv"},"source":["## 1.1.Test"]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":316},"id":"-dycWpSbZePw","executionInfo":{"status":"error","timestamp":1627113007459,"user_tz":-540,"elapsed":3810,"user":{"displayName":"­박민규 / 학생 / 전기·정보공학부","photoUrl":"","userId":"15454198223134513846"}},"outputId":"81116439-a509-483b-ff1d-294b653da064"},"source":["agent = DDPGAgent(4, 2, 3, 32, 32)\n","action = agent.act(np.array([3., -1., 2., -5.]))\n","print(action)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-d6b04cee14a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDDPGAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m5.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-a0749fc3e500>\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# torch tensor to numpy ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# remove extra dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mact_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'act_tensor' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"UJE6704wZePw"},"source":["# 2. Implement one-step param update"]},{"cell_type":"code","metadata":{"id":"K75e7LJpZePx"},"source":["def update(agent, replay_buf, gamma, actor_optim, critic_optim, target_actor, target_critic, tau, batch_size):\n","    # agent : agent with networks to be trained\n","    # replay_buf : replay buf from which we sample a batch\n","    # actor_optim / critic_optim : torch optimizers\n","    # tau : parameter for soft target update\n","    \n","    batch = replay_buf.sample_batch(batch_size=batch_size)\n","\n","    # target construction does not need backward ftns\n","    with torch.no_grad():\n","        # unroll batch\n","        obs = torch.Tensor(batch.obs).to(device)\n","        act = torch.Tensor(batch.act).to(device)\n","        next_obs = torch.Tensor(batch.next_obs).to(device)\n","        rew = torch.Tensor(batch.rew).to(device)\n","        done = torch.Tensor(batch.done).to(device)\n","        \n","        ################\n","        # train critic #\n","        ################\n","        mask = 1. - done\n","        target = rew + gamma * mask * target_critic(next_obs, target_actor(next_obs))\n","    \n","    out = agent.critic(obs, act)\n","\n","    # TODO : Build critic MSELoss by yourself!\n","    # Hint : use torch.mean\n","    #critic_loss = torch.mean()\n","    \n","    critic_optim.zero_grad()\n","    critic_loss.backward()\n","    critic_optim.step()\n","    \n","    ###############\n","    # train actor #\n","    ###############\n","    \n","    # freeze critic during actor training (why?)\n","    for p in agent.critic.parameters():\n","        p.requires_grad_(False)\n","    \n","    actor_loss = -torch.mean(agent.critic(obs, agent.actor(obs)))\n","    \n","    actor_optim.zero_grad()\n","    actor_loss.backward()\n","    actor_optim.step()\n","    \n","    \n","    # unfreeze critic after actor training\n","    for p in agent.critic.parameters():\n","        p.requires_grad_(True)\n","        \n","    # soft target update (both actor & critic network)\n","    for p, targ_p in zip(agent.actor.parameters(), target_actor.parameters()):\n","        targ_p.data.copy_((1. - tau) * targ_p + tau * p)\n","    for p, targ_p in zip(agent.critic.parameters(), target_critic.parameters()):\n","        targ_p.data.copy_((1. - tau) * targ_p + tau * p)\n","        \n","        \n","    return"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jQh-cLQ0ZePy"},"source":["def evaluate(agent, env, num_episodes=5):\n","\n","    sum_scores = 0.\n","    \n","    for i in range(num_episodes):\n","        obs = env.reset()\n","        done = False\n","        score = 0.\n","        \n","        while not done:\n","            action = agent.act(obs)\n","            obs, rew, done, _ = env.step(action)\n","            score += rew\n","        sum_scores += score\n","    avg_score = sum_scores / num_episodes\n","    \n","    return avg_score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QrosDS4ZZePy"},"source":["# 3. Combining these, we finally have..."]},{"cell_type":"code","metadata":{"id":"7sQTm_8RZePy"},"source":["def train(agent, env, gamma, \n","          actor_lr, critic_lr, tau, noise_std,\n","          ep_len, num_updates, batch_size,\n","          init_buffer=5000, buffer_size=100000,\n","          start_train=2000, train_interval=50,\n","          eval_interval=2000, snapshot_interval=10000, path=None):\n","    \n","    target_actor = copy.deepcopy(agent.actor)\n","    target_critic = copy.deepcopy(agent.critic)\n","    \n","    # freeze target networks\n","    for p in target_actor.parameters():\n","        p.requires_grad_(False)\n","    for p in target_critic.parameters():\n","        p.requires_grad_(False)\n","\n","    actor_optim = Adam(agent.actor.parameters(), lr=actor_lr)\n","    critic_optim = Adam(agent.critic.parameters(), lr=critic_lr)\n","    \n","    if path is not None:\n","        recover_snapshot(path, agent.actor, agent.critic,\n","                   target_actor, target_critic,\n","                   actor_optim, critic_optim,\n","                   device=device\n","                  )\n","        # load snapshot\n","    \n","    obs_dim = env.observation_space.shape[0]\n","    act_dim = env.action_space.shape[0]\n","    ctrl_range = env.action_space.high[0]\n","    \n","    replay_buf = ReplayBuffer(obs_dim, act_dim, buffer_size)\n","    \n","    save_path = './snapshots/'\n","    os.makedirs(save_path, exist_ok=True)\n","    \n","    # main loop\n","    obs = env.reset()\n","    done = False\n","    step_count = 0\n","    \n","    for t in tqdm(range(num_updates + 1)):\n","        if t < init_buffer:\n","            # perform random action until we collect sufficiently many samples\n","            # this is for exploration purpose\n","            action = env.action_space.sample()\n","        else:\n","            # executes noisy action\n","            # a_t = \\pi(s_t) + N(0, \\sigma^2)\n","            action = agent.act(obs) + noise_std * np.random.randn(act_dim)\n","            action = np.clip(action, -ctrl_range, ctrl_range)\n","            \n","        next_obs, rew, done, _ = env.step(action)\n","        step_count += 1\n","        if step_count == ep_len:\n","            # if the next_state is not terminal but done is set to True by gym env wrapper\n","            done = False\n","            \n","        replay_buf.append(obs, action, next_obs, rew, done)\n","        obs = next_obs\n","        \n","        if done == True or step_count == ep_len:\n","            # reset environment if current environment reaches a terminal state \n","            # or step count reaches predefined length\n","            obs = env.reset()\n","            done = False\n","            step_count = 0\n","            # score = evaluate(agent, env)\n","            # print('[iteration {}] evaluation score : {}'.format(t, score))\n","        \n","        \n","        if t > start_train and t % train_interval == 0:\n","            # start training after fixed number of steps\n","            # this may mitigate overfitting of networks to the \n","            # small number of samples collected during the initial stage of training\n","            for _ in range(train_interval):\n","                update(agent,\n","                       replay_buf,\n","                       gamma,\n","                       actor_optim,\n","                       critic_optim,\n","                       target_actor,\n","                       target_critic,\n","                       tau,\n","                       batch_size\n","                      )\n","        if t % snapshot_interval == 0:\n","            snapshot_path = save_path + 'iter{}_'.format(t)\n","            # save weight & training progress\n","            save_snapshot(snapshot_path, agent.actor, agent.critic,\n","                          target_actor, target_critic,\n","                          actor_optim, critic_optim)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FWwB76w-ZePz"},"source":["# 4. Let's test the code!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0vdCRnK8ZeP0","executionInfo":{"status":"ok","timestamp":1627113110337,"user_tz":-540,"elapsed":334,"user":{"displayName":"­박민규 / 학생 / 전기·정보공학부","photoUrl":"","userId":"15454198223134513846"}},"outputId":"3f4f4c3c-12dd-4b55-9e21-7d6f43a139d3"},"source":["env = gym.make('LunarLanderContinuous-v2')\n","obs_dim = env.observation_space.shape[0]\n","act_dim = env.action_space.shape[0]\n","ctrl_range = env.action_space.high[0]\n","\n","print('observation space dim : {} / action space dim : {}'.format(obs_dim, act_dim))\n","print('ctrl range : ', ctrl_range)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["observation space dim : 8 / action space dim : 2\n","ctrl range :  1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iu6VftswZeP0"},"source":["agent = DDPGAgent(obs_dim=obs_dim, act_dim=act_dim, ctrl_range=ctrl_range, hidden1=256, hidden2=256)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cYwH-XeyZeP0"},"source":["gamma = 0.99\n","actor_lr = 1e-4\n","critic_lr = 1e-3\n","tau = 1e-3\n","noise_std = 0.1\n","ep_len = 1000\n","num_updates = 200000\n","batch_size = 128"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hUJe2AmZZeP1"},"source":["train(agent, env, gamma,\n","      actor_lr, critic_lr, tau, noise_std,\n","      ep_len, num_updates, batch_size,\n","      init_buffer=5000, buffer_size=100000,\n","      start_train=2000, train_interval=50,\n","      eval_interval=5000\n","     )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IDxfKC3tZeP1"},"source":["# 5. Watch the trained agent!"]},{"cell_type":"code","metadata":{"id":"dTFs97dPb8n5"},"source":["if colab:\n","    import gym\n","    from gym.wrappers import Monitor\n","    import glob\n","    import io\n","    import base64\n","    from IPython.display import HTML\n","    from pyvirtualdisplay import Display\n","    from IPython import display as ipythondisplay\n","\n","    display = Display(visible=0, size=(1400, 900))\n","    display.start()\n","\n","    def show_video():\n","      mp4list = glob.glob('video/*.mp4')\n","      if len(mp4list) > 0:\n","        mp4 = mp4list[0]\n","        video = io.open(mp4, 'r+b').read()\n","        encoded = base64.b64encode(video)\n","        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n","                    loop controls style=\"height: 400px;\">\n","                    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n","                </video>'''.format(encoded.decode('ascii'))))\n","      else: \n","        print(\"Could not find video\")\n","        \n","\n","    def wrap_env(env):\n","      env = Monitor(env, './video', force=True)\n","      return env\n","\n","    env = wrap_env(env)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455},"id":"JC5Z6NI0ZeP1","executionInfo":{"status":"ok","timestamp":1627113219788,"user_tz":-540,"elapsed":3931,"user":{"displayName":"­박민규 / 학생 / 전기·정보공학부","photoUrl":"","userId":"15454198223134513846"}},"outputId":"1b632efc-8930-4a41-ac40-b3c22dde2a2d"},"source":["env = gym.make('LunarLanderContinuous-v2')\n","if colab:\n","  env = wrap_env(env)\n","obs = env_reset()\n","done = False\n","score = 0.\n","\n","for _ in range(1000):\n","    env.render(mode='human')\n","    obs, rew, _, _ = env.step(agent.act(obs))\n","    score += rew\n","print('score : ', score)\n","env.close()\n","\n","if colab:\n","    show_video()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["loading pre-trained weight...\n","score :  -51008.39558069934\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<video alt=\"test\" autoplay \n","                    loop controls style=\"height: 400px;\">\n","                    <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n","                </video>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]}]}