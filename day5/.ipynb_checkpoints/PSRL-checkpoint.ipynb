{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class True_MDP():\n",
    "    def __init__(self):\n",
    "        self.s = 0\n",
    "    def swim(self,a):\n",
    "        if a == 0:\n",
    "            return self.move_left()\n",
    "        elif a == 1:\n",
    "            return self.move_right()\n",
    "\n",
    "    def move_left(self):\n",
    "        if self.s == 0:\n",
    "            return self.s, 0.005\n",
    "        elif self.s in [1, 2, 3, 4, 5]:\n",
    "            self.s -= 1\n",
    "            return self.s, 0\n",
    "\n",
    "    def move_right(self):\n",
    "        coin = random.random()\n",
    "        if self.s == 5:\n",
    "            if coin < 0.6:\n",
    "                return self.s, 1\n",
    "            else:\n",
    "                self.s -= 1\n",
    "                return self.s, 0\n",
    "        if self.s in [1, 2, 3, 4]:\n",
    "            if coin < 0.35:\n",
    "                self.s += 1\n",
    "                return self.s, 0\n",
    "            elif coin < 0.4:\n",
    "                self.s -= 1\n",
    "                return self.s, 0\n",
    "            else:\n",
    "                return self.s, 0\n",
    "        if self.s == 0:\n",
    "            if coin < 0.6:\n",
    "                self.s += 1\n",
    "                return self.s, 0\n",
    "            else:\n",
    "                return self.s, 0\n",
    "\n",
    "    def get_state(self):\n",
    "        return self.s\n",
    "\n",
    "    def reset(self):\n",
    "        self.s=0\n",
    "        return self.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicProgramming():\n",
    "    def __init__(self,psample,rsample):\n",
    "        self.theta=0.0001\n",
    "        self.psample=psample\n",
    "        self.rsample=rsample\n",
    "\n",
    "    def One_step_LookAhead(self,v):\n",
    "        A = np.zeros((6,2))\n",
    "        inner_product=np.zeros((6,2))\n",
    "        for s in range(6):\n",
    "            for a in range(2):\n",
    "                for s_prime in range(6):\n",
    "                    inner_product[int(s)][int(a)] += self.psample[int(s)][int(a)][int(s_prime)]*v[int(s_prime)]\n",
    "        \n",
    "        for s in range(6):\n",
    "          for a in range(2):\n",
    "            A[int(s)][int(a)] = self.rsample[int(s)][int(a)] + 0.99*inner_product[int(s)][int(a)]\n",
    "        \n",
    "        return A\n",
    "    def value_iteration(self):\n",
    "        V=np.zeros(6)\n",
    "        while True:\n",
    "            delta = 0\n",
    "            for s in range(6):\n",
    "                v=V[s]\n",
    "                A = self.One_step_LookAhead(V)\n",
    "                best_action_value = np.max(A[s])\n",
    "                V[s] = best_action_value      \n",
    "                delta = max(delta, np.abs(v - V[s]))            \n",
    "            if delta < self.theta:\n",
    "                break\n",
    "        policy = np.zeros(6)\n",
    "        for s in range(6):\n",
    "            # One step lookahead to find the best action for this state\n",
    "            A = self.One_step_LookAhead(V)\n",
    "            policy[s] = np.argmax(A[s])\n",
    "        return policy, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class policy_evaluation():\n",
    "    def __init__(self,psample,rsample,policy):\n",
    "        self.theta=0.0001\n",
    "        self.psample=psample\n",
    "        self.rsample=rsample\n",
    "        self.policy=policy\n",
    "\n",
    "    def One_step_LookAhead(self,v):\n",
    "        v = np.zeros(6)\n",
    "        inner_product=np.zeros((6,2))\n",
    "        for s in range(6):\n",
    "          for s_prime in range(6):\n",
    "            inner_product[int(s)][int(self.policy[s])] += self.psample[int(s)][int(self.policy[s])][int(s_prime)]*v[int(s_prime)]\n",
    "        \n",
    "        for s in range(6):\n",
    "          v[s] = self.rsample[int(s)][int(self.policy[s])] + 0.99*inner_product[int(s)][int(self.policy[s])]\n",
    "        \n",
    "        return v\n",
    "\n",
    "    def value_iteration(self):\n",
    "        V=np.zeros(6)\n",
    "        while True:\n",
    "            delta = 0\n",
    "            for s in range(6):\n",
    "                v=V[s]\n",
    "                V = self.One_step_LookAhead(V)\n",
    "                delta = max(delta, np.abs(V[s]-v))\n",
    "            if delta < self.theta:\n",
    "                break\n",
    "        return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_rsample=np.zeros((6,2))\n",
    "true_rsample[0,0]=0.005\n",
    "true_rsample[5,1]=0.6\n",
    "true_psample=np.zeros((6,2,6))\n",
    "true_psample[0,0,0]=1\n",
    "true_psample[0,1,0]=0.4\n",
    "true_psample[0,1,1]=0.6\n",
    "true_psample[1,0,0]=1\n",
    "true_psample[1,1,1]=0.6\n",
    "true_psample[1,1,0]=0.05\n",
    "true_psample[1,1,2]=0.35\n",
    "true_psample[2,0,1]=1\n",
    "true_psample[2,1,2]=0.6\n",
    "true_psample[2,1,1]=0.05\n",
    "true_psample[2,1,3]=0.35\n",
    "true_psample[3,0,2]=1\n",
    "true_psample[3,1,3]=0.6\n",
    "true_psample[3,1,2]=0.05\n",
    "true_psample[3,1,4]=0.35\n",
    "true_psample[4,0,3]=1\n",
    "true_psample[4,1,4]=0.6\n",
    "true_psample[4,1,3]=0.05\n",
    "true_psample[4,1,5]=0.35\n",
    "true_psample[5,0,4]=1\n",
    "true_psample[5,1,4]=0.4\n",
    "true_psample[5,1,5]=0.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSRL():\n",
    "  env=True_MDP()\n",
    "  mu=np.zeros((6,2))\n",
    "  precision=np.ones((6,2))\n",
    "  alpha = np.ones((6, 2, 6))\n",
    "  sigma=1\n",
    "  regret=0\n",
    "  df=pd.DataFrame()\n",
    "  visit = np.zeros((6,2))\n",
    "  for m in range(50):\n",
    "    for episode in range(5000):\n",
    "        s=0\n",
    "        alpha_update = np.zeros((6, 2, 6))\n",
    "        mu_update = np.zeros((6,2))\n",
    "        precision_update = np.ones((6,2))\n",
    "        b=[]\n",
    "        for i in range(6):\n",
    "            for j in range(2):\n",
    "                for k in range(6):\n",
    "                    b.append(alpha[i][j][k])\n",
    "        c=np.random.dirichlet(b)\n",
    "        psample = np.zeros((6,2,6))\n",
    "        for i in range(6):\n",
    "            for j in range(2):\n",
    "                for k in range(6):\n",
    "                    psample[i][j][k]=c[12*(i-1)+6*(j-1)+k]\n",
    "        rsample = np.zeros((6,2))\n",
    "        for i in range(6):\n",
    "            for j in range(2):\n",
    "                rsample[i][j]=np.random.normal(mu[i][j],1/precision[i][j])\n",
    "       \n",
    "        policy,v=DynamicProgramming(psample,rsample).value_iteration()\n",
    "        history=[]\n",
    "        for time_step in range(20):\n",
    "            a=policy[s]\n",
    "            s_prime, r, = env.swim(a)\n",
    "            history.append((s, a, r, s_prime))\n",
    "            s=s_prime\n",
    "\n",
    "        for transition in history[::-1]:\n",
    "            s,a,r,s_prime=transition\n",
    "            alpha[int(s)][int(a)][int(s_prime)]+=1\n",
    "            visit[int(s)][int(a)] +=1\n",
    "            mu[int(s)][int(a)] += (r-mu[int(s)][int(a)])/(visit[int(s)][int(a)]+1)\n",
    "            precision[int(s)][int(a)] += sigma\n",
    "        V=policy_evaluation(true_psample,true_rsample,policy).value_iteration()\n",
    "        regret +=v[0]-V[0]\n",
    "       \n",
    "      \n",
    "        df.loc[episode,m]=regret\n",
    "\n",
    "  df.mean(axis=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8d1c0d446046>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPSRL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-35b04a4f66f0>\u001b[0m in \u001b[0;36mPSRL\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mrsample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDynamicProgramming\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtime_step\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-179c5036b46e>\u001b[0m in \u001b[0;36mvalue_iteration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# One step lookahead to find the best action for this state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOne_step_LookAhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mpolicy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-179c5036b46e>\u001b[0m in \u001b[0;36mOne_step_LookAhead\u001b[0;34m(self, v)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ms_prime\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                     \u001b[0minner_product\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_prime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_prime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "PSRL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
